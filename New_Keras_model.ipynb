{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigation 1: This model is written in Keras with tensorflow backend. Keras is faster for initial work. And easier to read \n",
    "but not as granualar as pure tensorflow the idea is to move to full tensor flow once we have a working model. \n",
    "\n",
    "The model takes in a list of uuids \n",
    "creates integer dictionarys for them \n",
    "zero pads them to the appropiate size.\n",
    "\n",
    "The model takes in the n-1 observations and the target is the nth uuid.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.recurrent import LSTM \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Embedding, TimeDistributed\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################### Read in Data  #####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO NEED TO RUN THIS CELL. I have pickled the data \n",
    "\n",
    "# Reads in data and produces a dataframe df \n",
    "file_loc ='data/CustomerActions-Movies-TimedUUID-3days.csv.zip'\n",
    "def readData(file_loc):\n",
    "    data_dict={}\n",
    "    max_steps=0\n",
    "    lines_list=[]\n",
    "    with zipfile.ZipFile(file_loc, 'r') as z:\n",
    "        with z.open(z.namelist()[0]) as f:\n",
    "            for line in f:\n",
    "                line2= re.split(\",|~|\\\\n|\\\\n'\",str(line).replace(\"\\\\n'\",'\\n').strip())\n",
    "                lines_list.append(line2)\n",
    "                if len(line2)>max_steps:\n",
    "                    max_steps=len(line2)           \n",
    "        for i,v in enumerate(lines_list):   \n",
    "            lis2 = list(filter(None, v))\n",
    "            data_dict[i]= lis2 + [0]* (max_steps-len(lis2))\n",
    "        df= pd.DataFrame(data_dict).T\n",
    "        return data_dict,df,max_steps\n",
    "data_dict,df,max_steps = readData(file_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'32B0630488554327</td>\n",
       "      <td>1509559350</td>\n",
       "      <td>93d8663c-404f-4877-a665-c8797d8ae8e5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'32B0630488568972</td>\n",
       "      <td>1509572912</td>\n",
       "      <td>9ab4430a-5a6b-4d00-804e-74634be17a74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'32B0630488568974</td>\n",
       "      <td>1509462399</td>\n",
       "      <td>57f7fffe-1c02-4a73-90ed-1c46bde8c3e6</td>\n",
       "      <td>1509540077</td>\n",
       "      <td>edbf9d69-80ac-4b62-95a8-665792899168</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'32C0050489325572</td>\n",
       "      <td>1509394813</td>\n",
       "      <td>25163878-7573-4779-9b2e-63fda24ac838</td>\n",
       "      <td>1509574002</td>\n",
       "      <td>c1d1dcef-9552-4fb8-b812-ec7455b67c7e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'32C0060489462801</td>\n",
       "      <td>1509554398</td>\n",
       "      <td>b79710af-5540-49f5-993f-35c3235740e1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0           1                                     2   \\\n",
       "0  b'32B0630488554327  1509559350  93d8663c-404f-4877-a665-c8797d8ae8e5   \n",
       "1  b'32B0630488568972  1509572912  9ab4430a-5a6b-4d00-804e-74634be17a74   \n",
       "2  b'32B0630488568974  1509462399  57f7fffe-1c02-4a73-90ed-1c46bde8c3e6   \n",
       "3  b'32C0050489325572  1509394813  25163878-7573-4779-9b2e-63fda24ac838   \n",
       "4  b'32C0060489462801  1509554398  b79710af-5540-49f5-993f-35c3235740e1   \n",
       "\n",
       "           3                                     4  5  6  7  8  9  ... 66 67  \\\n",
       "0           0                                     0  0  0  0  0  0 ...  0  0   \n",
       "1           0                                     0  0  0  0  0  0 ...  0  0   \n",
       "2  1509540077  edbf9d69-80ac-4b62-95a8-665792899168  0  0  0  0  0 ...  0  0   \n",
       "3  1509574002  c1d1dcef-9552-4fb8-b812-ec7455b67c7e  0  0  0  0  0 ...  0  0   \n",
       "4           0                                     0  0  0  0  0  0 ...  0  0   \n",
       "\n",
       "  68 69 70 71 72 73 74 75  \n",
       "0  0  0  0  0  0  0  0  0  \n",
       "1  0  0  0  0  0  0  0  0  \n",
       "2  0  0  0  0  0  0  0  0  \n",
       "3  0  0  0  0  0  0  0  0  \n",
       "4  0  0  0  0  0  0  0  0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df has dimensions (506548, 75)\n",
    "df.to_pickle('data/3days_df.gzip','gzip')\n",
    "temp= gzip.open('data/3days_df.pkl')\n",
    "df=pd.read_pickle(temp)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################### PreProcessing  #####################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take only the uuids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "only_uuids = df.loc[:,::2] #select only uuid \n",
    "only_timestamps = df.loc[:,1::2]  #select only timestamp "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary so each uuid has a unique id and a reverse dictionary so we can give an id and get the uuid back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_uuid = set([])\n",
    "for i in range(2,max_steps,2): #start from 2 because 1 is the device id \n",
    "    set_uuid.update(only_uuids.loc[:,i])\n",
    "\n",
    "vocab_size = len(set_uuid) #length of vocabulary\n",
    "dictionary={}  # uuid:int\n",
    "reversed_dictionary={}  #int:uuid\n",
    "# convert uuid to numbers \n",
    "for i,value in enumerate(set_uuid):\n",
    "    reversed_dictionary[i] = value\n",
    "    dictionary[value]=i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'667e6bc0-961c-4a8a-9a55-7e2862d668ea'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reversed_dictionary[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################### Data Filtering  #####################\n",
    "\n",
    "Here we subset the data by how many movies a particular customer has watched and convert it to a matrix.\n",
    "We don't use the device id currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watched_more = 4\n",
    "watched_less =len(only_uuids.columns)\n",
    "four_or_more = only_uuids.loc[(np.sum(only_uuids!=0,axis=1)>watched_more) & (np.sum(only_uuids!=0,axis=1)<watched_less),:]\n",
    "four_or_more=four_or_more.loc[:,2:].as_matrix() #0 is device id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have about 74k observations\n",
    "four_or_more.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMCYVSdJgTCqSpMGYVCRJgzGpSJIG8/8Bs6VMYZcRXoYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1824d85fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_views=(four_or_more != 0).astype(int).sum(axis=1)\n",
    "plt.hist(n_views,bins=20)\n",
    "plt.xlabel('number of movies watched')\n",
    "plt.ylabel('number of customers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert all the uuid into ids using the dictionary we created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# integer encode input data\n",
    "input_encoded_all=[]\n",
    "for i in range(len(four_or_more)):\n",
    "    input_encoded_all.append(list(filter(lambda x: x!=0 ,[dictionary[uuid] for uuid in four_or_more[i]])))\n",
    "\n",
    " \n",
    "#pad sequences\n",
    "max_len = max([len(seq) for seq in input_encoded_all])\n",
    "padded_data = pad_sequences(input_encoded_all,maxlen=max_len,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1494, 1494, 1494, 1494],\n",
       " [5102, 5284, 4271, 7040],\n",
       " [5086, 2457, 4966, 3962],\n",
       " [3901, 8169, 4735, 5343, 6175, 6374]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_encoded_all is an array of list, where each list is a customer watch history\n",
    "input_encoded_all[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0, 1494, 1494, 1494, 1494],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0, 5102, 5284, 4271, 7040],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0, 5086, 2457, 4966, 3962],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0, 3901, 8169, 4735, 5343, 6175, 6374]], dtype=int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padded_data is the input data but just padded with preceeding zeros to the max length of watches\n",
    "padded_data[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################### Batch generation  #####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# num_steps is the number of 'timesteps'. I have put timestep in qoutes because the timesteps are not evenly spaced \n",
    "# This generator will generate a training batch for the model\n",
    "\n",
    "num_steps=max_len-1\n",
    "\n",
    "def generate(pad_data,batch_size,num_steps):\n",
    "    x = np.zeros((batch_size, num_steps))\n",
    "    y = np.zeros((batch_size,num_steps,vocab_size))\n",
    "    current_idx=0\n",
    "    data_len= len(pad_data[current_idx])\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            x[i, :] = pad_data[i][:-1]\n",
    "            temp_y = pad_data[i][1:]\n",
    "            # convert all of temp_y into a one hot representation\n",
    "            y[i, :,:] = to_categorical(temp_y, num_classes=vocab_size)\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################### LSTM model #####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size=300 #number of hidden nodes in LSTM blocks (i.e. number of nodes for the input, forget and output gates )\n",
    "batch_size =50\n",
    "\n",
    "\n",
    "model = Sequential() #initialise a sequential model\n",
    "model.add(Embedding(vocab_size, hidden_size, input_length=num_steps)) #put the uuid into a vector representation with length equal to the number of hidden nodes\n",
    "model.add(LSTM(hidden_size, return_sequences=True)) # first lstm layer, we return all nodes output\n",
    "model.add(LSTM(hidden_size,return_sequences=True)) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(LSTM(hidden_size, return_sequences=True)) # last lstm layer, we return (all nodes output) this is optionally but I think its benefial. We can discus?\n",
    "model.add(TimeDistributed(Dense(vocab_size))) # apply a fully connected nn to each output \n",
    "model.add(Activation('softmax')) #logits --> probs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile the model \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam' ,metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 187s 2s/step - loss: 2.0985 - categorical_accuracy: 0.8180 - val_loss: 2.4931 - val_categorical_accuracy: 0.8117\n",
      "Epoch 2/50\n",
      "  8/100 [=>............................] - ETA: 2:51 - loss: 1.3330 - categorical_accuracy: 0.8262"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-ab6eaa0e1247>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m model.fit_generator(generate(padded_data[:5000],batch_size,num_steps), 5000//(batch_size), 50,\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                         validation_steps=200//batch_size)\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1274\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model \n",
    "# I have subset the data even more to just 5000 samples just for quicker iterations\n",
    "# and validation is 200 samples \n",
    "model.fit_generator(generate(padded_data[:5000],batch_size,num_steps), 5000//(batch_size), 50,\n",
    "                    validation_data=generate(padded_data[5000:5200],batch_size,num_steps),\n",
    "                        validation_steps=200//batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The high accuracy is decietful because most of the data are zeros so the accuracy will be high if it learns to predict zeros \n",
    "# but the last output( which we are interested in is wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################### Predictions #####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual : ['ea1f7105-f2a6-444d-998c-c72dd8f76fa0', 'ea1f7105-f2a6-444d-998c-c72dd8f76fa0']\n",
      "predicted : [0, 0]\n"
     ]
    }
   ],
   "source": [
    "# number of predictions wanted \n",
    "num_predict = 2\n",
    "\n",
    "true_print_out = []\n",
    "pred_print_out = []\n",
    "for i in range(num_predict):\n",
    "    data = next(generate(padded_data[:10],1,num_steps), 1)\n",
    "    prediction = model.predict(data[0])\n",
    "    actual = data[1][0]\n",
    "    predict_idx = np.argmax(prediction[:, -1, :])\n",
    "    actual = np.argmax(actual[num_steps-1, :])\n",
    "    true_print_out.append(reversed_dictionary[actual])\n",
    "    pred_print_out.append(reversed_dictionary[predict_idx])\n",
    "print('actual :',true_print_out)\n",
    "print('predicted :',pred_print_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
